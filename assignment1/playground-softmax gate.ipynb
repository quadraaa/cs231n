{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_forward(x):\n",
    "    exps = np.exp(x)\n",
    "    sexps = np.sum(exps, axis=1).reshape(-1,1)\n",
    "    divexps = (1/sexps).reshape(-1,1)\n",
    "    mul = exps * divexps\n",
    "    return mul, {\"exps\":exps, \"sexps\":sexps, \"divexps\":divexps}\n",
    "\n",
    "def softmax_backward(dout, cache, print_=False):\n",
    "    softmax_grad = {}\n",
    "    \n",
    "    dexps_0 = cache[\"divexps\"] * dout\n",
    "    softmax_grad[\"dexps_0\"] = dexps_0\n",
    "\n",
    "    ddivexps = np.sum(cache[\"exps\"] * dout, axis=1).reshape(-1,1)\n",
    "    softmax_grad[\"ddivexps\"] = ddivexps\n",
    "    \n",
    "    dsexps = -1.0/(cache[\"sexps\"]**2) * ddivexps\n",
    "    softmax_grad[\"dsexps\"] = dsexps\n",
    "    \n",
    "    dexps_1 = dsexps/(np.sum(cache[\"exps\"], axis=1).reshape(-1,1))*cache[\"exps\"]\n",
    "    softmax_grad[\"dexps_1\"] = dexps_1\n",
    "    \n",
    "    dx = cache[\"exps\"] * (dexps_0 + dexps_1)\n",
    "    softmax_grad[\"dx\"] = dx\n",
    "    \n",
    "    if print_:\n",
    "        print(\"dexps_0\")\n",
    "        print(dexps_0.shape)\n",
    "        print(dexps_0)\n",
    "        print(\"ddivexps\")\n",
    "        print(ddivexps.shape)\n",
    "        print(ddivexps)\n",
    "        print(\"dsexps\")\n",
    "        print(dsexps.shape)\n",
    "        print(dsexps)\n",
    "        print(\"dexps_1\")\n",
    "        print(dexps_1.shape)\n",
    "        print(dexps_1)\n",
    "        print(\"dx\")\n",
    "        print(dx.shape)\n",
    "        print(dx)\n",
    "\n",
    "    return softmax_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([[1., 2., 3.], [4., 5., 5.]])\n",
    "N, D = a.shape[0], a.shape[1]\n",
    "delta = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax, cache = softmax_forward(a)\n",
    "softmax_grad = softmax_backward(dout = np.ones(a.shape), cache=cache)\n",
    "\n",
    "# softmax_mod = {}\n",
    "# cache_mod = {}\n",
    "grad_manual = np.zeros((N,D))\n",
    "for i in range(N):\n",
    "    for j in range(D):\n",
    "        a_mod = a.copy()\n",
    "        a_mod[i, j] = a_mod[i, j] + delta\n",
    "        softmax_mod, cache_mod = softmax_forward(a_mod)\n",
    "        grad_manual[i,j] = (softmax_mod[i,j] - softmax[i,j])/delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dexps_0': array([[0.0331204 , 0.0331204 , 0.0331204 ],\n",
       "        [0.00284556, 0.00284556, 0.00284556]]),\n",
       " 'ddivexps': array([[ 30.19287485],\n",
       "        [351.42446824]]),\n",
       " 'dsexps': array([[-0.0331204 ],\n",
       "        [-0.00284556]]),\n",
       " 'dexps_1': array([[-0.00298185, -0.0081055 , -0.02203304],\n",
       "        [-0.00044209, -0.00120173, -0.00120173]]),\n",
       " 'dx': array([[0.08192507, 0.18483645, 0.22269543],\n",
       "        [0.13122493, 0.24396563, 0.24396563]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dexps_0 expected to be:\n",
      "[[0.0331204  0.0331204  0.0331204 ]\n",
      " [0.00284556 0.00284556 0.00284556]]\n",
      "dexps_1 expected to be:\n",
      "[[-0.00298185 -0.0081055  -0.02203304]\n",
      " [-0.00044209 -0.00120173 -0.00120173]]\n"
     ]
    }
   ],
   "source": [
    "print(\"dexps_0 expected to be:\")\n",
    "print(grad_manual/cache[\"exps\"] - softmax_grad[\"dexps_1\"])\n",
    "print(\"dexps_1 expected to be:\")\n",
    "dexps_1_exp = (grad_manual/cache[\"exps\"] - softmax_grad[\"dexps_0\"])\n",
    "print(dexps_1_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08192507, -0.02203305, -0.05989203],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_copy = a.copy()\n",
    "x_copy[0,0] += 1e-7\n",
    "(softmax_forward(x_copy)[0] - softmax_forward(a)[0])/1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09003058, 0.24472847, 0.66524095],\n",
       "       [0.1553624 , 0.4223188 , 0.4223188 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_forward(x_copy)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
