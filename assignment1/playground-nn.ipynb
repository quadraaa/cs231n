{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_forward(x):\n",
    "    exps = np.exp(x)\n",
    "    sexps = np.sum(exps, axis=1).reshape(-1,1)\n",
    "    divexps = (1/sexps).reshape(-1,1)\n",
    "    mul = exps * divexps\n",
    "    return mul, {\"exps\":exps, \"sexps\":sexps, \"divexps\":divexps}\n",
    "\n",
    "def softmax_backward(dout, cache, print_=False):\n",
    "    softmax_grad = {}\n",
    "    \n",
    "    dexps_0 = cache[\"divexps\"] * dout\n",
    "    softmax_grad[\"dexps_0\"] = dexps_0\n",
    "\n",
    "    ddivexps = np.sum(cache[\"exps\"] * dout, axis=1).reshape(-1,1)\n",
    "    softmax_grad[\"ddivexps\"] = ddivexps\n",
    "    \n",
    "    dsexps = -1.0/(cache[\"sexps\"]**2) * ddivexps\n",
    "    softmax_grad[\"dsexps\"] = dsexps\n",
    "    \n",
    "    # dexps_1 = dsexps/(np.sum(cache[\"exps\"], axis=1).reshape(-1,1))*cache[\"exps\"]\n",
    "    dexps_1 = dsexps * np.ones(dout.shape)\n",
    "    softmax_grad[\"dexps_1\"] = dexps_1\n",
    "    \n",
    "    dexps = dexps_0 + dexps_1\n",
    "    softmax_grad[\"dexps\"] = dexps\n",
    "    \n",
    "    dx = cache[\"exps\"] * (dexps)\n",
    "    softmax_grad[\"dx\"] = dx\n",
    "    \n",
    "    if print_:\n",
    "        print(\"dexps_0:\")\n",
    "        print(dexps_0.shape)\n",
    "        print(dexps_0)\n",
    "        print(\"ddivexps:\")\n",
    "        print(ddivexps.shape)\n",
    "        print(ddivexps)\n",
    "        print(\"dsexps:\")\n",
    "        print(dsexps.shape)\n",
    "        print(dsexps)\n",
    "        print(\"dexps_1:\")\n",
    "        print(dexps_1.shape)\n",
    "        print(dexps_1)\n",
    "        print(\"dexps:\")\n",
    "        print(dexps.shape)\n",
    "        print(dexps)\n",
    "        print(\"dx:\")\n",
    "        print(dx.shape)\n",
    "        print(dx)\n",
    "\n",
    "    return softmax_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.asarray([[0.5, 0.4, 0.3]])\n",
    "w2 = np.asarray([[0.8, -0.1], [1.3, 0.15], [-1.1, 0.95,]])\n",
    "b1 = np.asarray([-1, 3, 1])\n",
    "b2 = np.asarray([0.65, 0.8])\n",
    "x = np.asarray([2, -5]).reshape(-1,1)\n",
    "y = [1,0]\n",
    "reg = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.18, 2.09],\n",
       "       [1.3 , 0.15]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_relu, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax = [[0.71909966 0.28090034]\n",
      " [0.73105858 0.26894142]]\n",
      "neg_log = [1.26975533 0.31326169]\n",
      "loss_data = 0.7915085063990551\n",
      "loss_reg = 0.8518750000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6433835063990552"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_out = np.dot(x, w1)\n",
    "l1_lin = w1_out + b1\n",
    "l1_relu = np.maximum(l1_lin, 0)\n",
    "w2_out = np.dot(l1_relu, w2)\n",
    "l2_lin = w2_out + b2\n",
    "softmax, cache = softmax_forward(l2_lin)\n",
    "#softmax = np.exp(l2_lin)/np.sum(np.exp(l2_lin), axis=1).reshape(-1,1)\n",
    "print(\"softmax = {}\".format(softmax))\n",
    "neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "loss_data = np.mean(neg_log)\n",
    "print(\"neg_log = {}\".format(neg_log))\n",
    "print(\"loss_data = {}\".format(loss_data))\n",
    "w1_l2 = np.sum(w1 * w1)\n",
    "w2_l2 = np.sum(w2 * w2)\n",
    "b1_l2 = np.sum(b1 * b1)\n",
    "b2_l2 = np.sum(b2 * b2)\n",
    "loss_reg = (w1_l2 +w2_l2 +b1_l2 +b2_l2 )*reg\n",
    "print(\"loss_reg = {}\".format(loss_reg))\n",
    "loss = loss_data + loss_reg\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsoftmax = np.asarray([[0.0, -1.78], [-0.6839, 0.0]])\n",
    "#dsoftmax = softmax_backward(np.asarray(dsoftmax), cache, False)\n",
    "dl2_lin = softmax_backward(np.asarray(dsoftmax), cache, False)\n",
    "db2 = np.sum(dl2_lin[\"dx\"], axis=0) + 2 * 0.05 * b2\n",
    "dw2 = np.dot(l1_relu.T, dl2_lin[\"dx\"]) + 2 * 0.05 * w2\n",
    "dl1_relu = np.dot(dl2_lin[\"dx\"], w2.T)\n",
    "dl1_lin = np.maximum(l1_lin, 0)\n",
    "dl1_lin[dl1_lin > 0] = 1\n",
    "dl1_lin *= dl1_relu\n",
    "db1 = np.sum(dl1_lin, axis=0) + 2 * 0.05 * b1\n",
    "dw1 = np.dot(x.T, dl1_lin) + 2 * 0.05 * w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05      ,  1.6401306 , -1.44416199]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x.T, dl1_lin) + 2 * 0.05 * w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05      ,  1.6401306 , -1.44416199]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6971889732199088"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_new = w1.copy()\n",
    "w1_new[0, 0] += 1e-10\n",
    "(nn_loss(w1_new, w2, b1, b2, x, y) - nn_loss(w1, w2, b1, b2, x, y))/1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05      ,  1.6401306 , -1.44416199]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,3) and (2,1) not aligned: 3 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-341-fcb506b1c02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl1_lin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,3) and (2,1) not aligned: 3 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(dl1_lin, x) + 2 * 0.05 * w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dl1_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_l1_lin_loss(w1, w2, b1, b2, x, y, l1_lin, reg=0.05):\n",
    "    l1_relu = np.maximum(l1_lin, 0)\n",
    "    w2_out = np.dot(l1_relu, w2)\n",
    "    l2_lin = w2_out + b2\n",
    "    softmax, cache = softmax_forward(l2_lin)\n",
    "    \n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.323594884221734"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_lin_new = l1_lin.copy()\n",
    "l1_lin_new[0,0] += 1e-8\n",
    "(from_l1_lin_loss(w1, w2, b1, b2, x, y, l1_lin_new) -\n",
    " from_l1_lin_loss(w1, w2, b1, b2, x, y, l1_lin))/1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6433835063990552"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_l1_lin_loss(w1, w2, b1, b2, x, y, l1_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dl1_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_l1_relu_loss(w1, w2, b1, b2, x, y, l1_relu, reg=0.05):\n",
    "    w2_out = np.dot(l1_relu, w2)\n",
    "    l2_lin = w2_out + b2\n",
    "    softmax, cache = softmax_forward(l2_lin)\n",
    "    \n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2756649575275105"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_relu_new = l1_relu.copy()\n",
    "l1_relu_new[1,2] += 1e-8\n",
    "(from_l1_relu_loss(w1, w2, b1, b2, x, y, l1_relu_new) -\n",
    " from_l1_relu_loss(w1, w2, b1, b2, x, y, l1_relu))/1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32359653,  0.41348446, -0.737081  ],\n",
       "       [-0.12101661, -0.15463234,  0.27564895]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl1_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dw2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_w2_out_loss(w1, w2, b1, b2, x, y, w2_out, reg=0.05):\n",
    "    \n",
    "    l2_lin = w2_out + b2\n",
    "    softmax, cache = softmax_forward(l2_lin)\n",
    "    \n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1344707012407298"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_out_new = w2_out.copy()\n",
    "w2_out_new[1,0] += 1e-8\n",
    "(from_w2_out_loss(w1, w2, b1, b2, x, y, w2_out_new) -\n",
    " from_w2_out_loss(w1, w2, b1, b2, x, y, w2_out))/1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_loss(w1, w2, b1, b2, x, y, reg=0.05):\n",
    "    w1_out = np.dot(x, w1)\n",
    "    l1_lin = w1_out + b1\n",
    "    l1_relu = np.maximum(l1_lin, 0)\n",
    "    w2_out = np.dot(l1_relu, w2)\n",
    "    l2_lin = w2_out + b2\n",
    "    softmax, cache = softmax_forward(l2_lin)\n",
    "    \n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4802780395607442"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_new = w2.copy()\n",
    "w2_new[2, 1] += 1e-10\n",
    "(nn_loss(w1, w2_new, b1, b2, x, y) - nn_loss(w1, w2, b1, b2, x, y))/1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw2_empirical = np.asarray([[0.08, -0.01],\n",
    "                            [1.3618186578412406, -1.2168186458438868],\n",
    "                            [0.4652797258586361, -0.48027972709974165]\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.38777878e-17,  1.73472348e-18],\n",
       "       [-1.49215867e-05,  1.49335841e-05],\n",
       "       [-3.00280319e-06,  3.00156208e-06]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw2_empirical - dw2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_loss(w1, w2, b1, b2, x, y, reg=0.05):\n",
    "    w1_out = np.dot(x, w1)\n",
    "    l1_lin = w1_out + b1\n",
    "    l1_relu = np.maximum(l1_lin, 0)\n",
    "    w2_out = np.dot(l1_relu, w2)\n",
    "    l2_lin = w2_out + b2\n",
    "    softmax, cache = softmax_forward(l2_lin)\n",
    "    \n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1450791042856281"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_new = b2.copy()\n",
    "b2_new[1] += 1e-7\n",
    "(nn_loss(w1, w2, b1, b2_new, x, y) - nn_loss(w1, w2, b1, b2, x, y))/1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.65, 0.8 ]), array([0.65, 0.8 ]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2, b2_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_softmax_loss(softmax, y, w1, w2, b1, b2, reg=0.05):\n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "    # print(\"neg_log = {}\".format(neg_log))\n",
    "    # print(\"loss_data = {}\".format(loss_data))\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "    # print(loss_reg)\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6433835063990552"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_softmax_loss(softmax, y, w1, w2, b1, b2, reg=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71909966, 0.28090034],\n",
       "       [0.73105858, 0.26894142]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7799906437687696"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_new = softmax.copy()\n",
    "softmax_new[0,1] += 1e-8\n",
    "(from_softmax_loss(softmax_new, y, w1, w2, b1, b2, reg=0.05) - \n",
    " from_softmax_loss(softmax, y, w1, w2, b1, b2, reg=0.05))/1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71909966, 0.28090034],\n",
       "       [0.73105858, 0.26894142]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dl2_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_softmax_loss(l2_lin, x, y, w1, w2, b1, b2, reg=0.05):\n",
    "    softmax, cache = softmax_forward(l2_lin)\n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "    loss = loss_data + loss_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lin_new = l2_lin.copy()\n",
    "l2_lin_new[0,1] += 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.83, 2.89],\n",
       "       [1.95, 0.95]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6433835063990552"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_softmax_loss(l2_lin, x, y, w1, w2, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.35954981214558757"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(from_softmax_loss(l2_lin_new, x, y, w1, w2, b1, b2) \n",
    " - from_softmax_loss(l2_lin, x, y, w1, w2, b1, b2))/1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-f98aa03b7f79>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-f98aa03b7f79>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    -0.1344706612727009 0.1344707234451903\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "0.35954983435004806 -0.35954981214558757\n",
    "-0.1344706612727009 0.1344707234451903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35955171, -0.35955171],\n",
       "       [-0.1344629 ,  0.1344629 ]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsoftmax[\"dx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradients inside softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_exps_loss(exps, x, y, w1, w2, b1, b2, reg=0.05):\n",
    "    \n",
    "    sexps = np.sum(exps, axis=1).reshape(-1,1)\n",
    "    divexps = (1/sexps).reshape(-1,1)\n",
    "    softmax = exps * divexps\n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "    \n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    \n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "    loss = loss_data + loss_reg\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_orig = np.exp(l2_lin)\n",
    "exps_new = exps_orig.copy()\n",
    "exps_new[1, 0] += 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.06253823, 17.9933096 ],\n",
       "       [ 7.02868759,  2.58570966]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.06253823, 17.9933096 ],\n",
       "       [ 7.02868758,  2.58570966]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00],\n",
       "       [9.99999994e-09, 0.00000000e+00]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps_new - exps_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.019131674022787593"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(from_exps_loss(exps_new, x, y, w1, w2, b1, b2) \n",
    " - from_exps_loss(exps_orig, x, y, w1, w2, b1, b2))/1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### real gradient for exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dexps_empirical = np.asarray([[0.007805711632613566, -0.019982415722097358],\n",
    "[-0.019131674022787593, 0.052005355577477985]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00780571, -0.01998242],\n",
       "       [-0.01913167,  0.05200536]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexps_empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analytical gradient for exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00780573, -0.01998252],\n",
       "       [-0.01913058,  0.05200232]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsoftmax[\"dexps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00780573, 0.00780573],\n",
       "       [0.05200232, 0.05200232]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsoftmax[\"dexps_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.02778825],\n",
       "       [-0.0711329 ,  0.        ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsoftmax[\"dexps_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00780582, 0.05200427])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexps_empirical.sum(axis=1) - dsoftmax[\"dexps\"].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0121767 ,  0.03287368])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexps_empirical.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01998252, -0.01913058])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsoftmax[\"dexps\"].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00780571, 0.00780584],\n",
       "       [0.05200123, 0.05200536]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexps_empirical - dsoftmax[\"dexps_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_sexps_loss(exps, sexps, x, y, w1, w2, b1, b2, reg=0.05):\n",
    "\n",
    "    divexps = (1/sexps).reshape(-1,1)\n",
    "    softmax = exps * divexps\n",
    "    neg_log = -np.log(softmax[range(x.shape[0]), y])\n",
    "    loss_data = np.mean(neg_log)\n",
    "    \n",
    "    w1_l2 = np.sum(w1 * w1)\n",
    "    w2_l2 = np.sum(w2 * w2)\n",
    "    b1_l2 = np.sum(b1 * b1)\n",
    "    b2_l2 = np.sum(b2 * b2)\n",
    "    \n",
    "    loss_reg = (w1_l2 + w2_l2 + b1_l2 + b2_l2 )*reg\n",
    "    loss = loss_data + loss_reg\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexps_orig = np.sum(exps_orig, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00],\n",
       "       [1.00000008e-08]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexps_new = sexps_orig.copy()\n",
    "sexps_new[1, 0] += 1e-8\n",
    "sexps_new - sexps_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052005355577477985"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(from_sexps_loss(exps_orig, sexps_new, x, y, w1, w2, b1, b2) \n",
    " - from_sexps_loss(exps_orig, sexps_orig, x, y, w1, w2, b1, b2))/1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsexps_empirical = np.asarray([[0.007805711632613566],\n",
    "[0.052005355577477985]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00780571],\n",
       "       [0.05200536]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsexps_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00780573],\n",
       "       [0.05200232]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsoftmax[\"dsexps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
